[{"content":"\u003ch1 id=\"from-input-to-insight-exploring-ai-and-llms\"\u003eFrom Input to Insight: Exploring AI and LLMs\u003c/h1\u003e\n  \u003c!-- Inside AI Magic: Understanding LLM Processing --\u003e\n\u003cp\u003eHave you ever wondered how AI chatbots can grasp your questions and reply so effectively? This guide walks you through how they work, starting with basic ideas and moving to deeper technical insights. These chatbots backed by LLM\u0026rsquo;s processes information in a structured order, drawing on multiple sources to improve its responses. Each step below is enhanced with concepts from \u003ca href=\"https://blog.bytebytego.com/p/how-llms-see-the-world?utm_source=publication-search\"\u003eHow LLMs see the world\u003c/a\u003e, including in-depth details on tokens, embedding, positioning, and transformer mechanics.\u003c/p\u003e\n\u003ch2 id=\"table-of-contents\"\u003eTable of contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#visual-overview-of-llm-processing-flow\"\u003eOverview of LLM processing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#ai-made-simple-understanding-the-flowchart-and-transformers-with-a-library-analogy\"\u003eUnderstanding AI basics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#component-spotlights-key-elements-of-the-llm-process\"\u003eCore components of LLMs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#llm-landscape-comparing-leading-models\"\u003eExploring AI models and technology\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#agentic-systems-and-automated-workflows\"\u003eAgentic AI and workflows\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#references\"\u003eReferences\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"visual-overview-of-llm-processing-flow\"\u003eVisual overview of LLM processing flow\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-mermaid\" data-lang=\"mermaid\"\u003egraph TD\n    Input[\u0026#34;User Input\u0026#34;] --\u0026gt; RAG[\u0026#34;RAG\u0026#34;]\n    RAG --\u0026gt; VectorDB[\u0026#34;Vector DB\u0026#34;]\n    RAG --\u0026gt; MCP[\u0026#34;MCP Server\u0026#34;]\n    VectorDB --\u0026gt; LLM[\u0026#34;LLM\u0026#34;]\n    MCP --\u0026gt; LLM\n    RAG --\u0026gt; LLM\n    LLM --\u0026gt; Output[\u0026#34;Output\u0026#34;]\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-dot\" data-lang=\"dot\"\u003edigraph G {\n    rankdir=TB;\n    Input [label=\u0026#34;User Input\u0026#34;];\n    RAG [label=\u0026#34;RAG\u0026#34;];\n    VectorDB [label=\u0026#34;Vector DB\u0026#34;];\n    MCP [label=\u0026#34;MCP Server\u0026#34;];\n    LLM [label=\u0026#34;LLM\u0026#34;];\n    Output [label=\u0026#34;Output\u0026#34;];\n    Input -\u0026gt; RAG;\n    RAG -\u0026gt; VectorDB;\n    RAG -\u0026gt; MCP;\n    VectorDB -\u0026gt; LLM;\n    MCP -\u0026gt; LLM;\n    RAG -\u0026gt; LLM;\n    LLM -\u0026gt; Output;\n}\n\n\n## AI made simple: Understanding the flowchart and transformers with a library analogy\n\nThis analogy provides a foundational understanding of AI processes. As we progress, we\u0026#39;ll explore the technical details behind these components.\n\nWhether you\u0026#39;re new to technology or just curious, understanding how intelligent language systems like chatbots or AI assistants operate can feel a bit overwhelming at first. Let\u0026#39;s simplify it by breaking down the flowchart in this document and the concept of \u0026#34;transformers\u0026#34; (the core engine behind these systems) using relatable, everyday examples.\n\n**The Flow Chart Explained – Like a Helpful Team at a Library:**\nOur flowchart shows the steps an AI system takes to answer your questions. Imagine you’re at a magical library where a team works together to help you:\n\n- **User input:** This is you walking up to the librarian’s desk with a question, like “Tell me about dinosaurs.”\n- **RAG (Retrieval-Augmented Generation):** The head librarian doesn’t just guess the answer. They decide if they need extra books or articles to give you the best information. They send a helper to look for these resources.\n- **Vector DB (Database):** This is like a super-organized shelf of books and notes where everything is sorted by topics, not just titles. The helper quickly finds books about dinosaurs by matching the “idea” of your question to the right resources, even if you didn’t use the exact words.\n- **MCP Server:** Sometimes, the librarian calls a special expert—like a paleontologist—for up-to-date or unique facts about dinosaurs that aren’t in the library books.\n- **LLM (Large Language Model):** Now, the head librarian gathers all the information—from their own memory, the books, and the expert—and carefully thinks about how to explain it. They craft a clear story or answer about dinosaurs.\n- **Output:** Finally, the librarian shares the answer in simple words, making it easy to understand, like “Dinosaurs were huge creatures that lived millions of years ago…”\n\nThe arrows in the flowchart show how information moves from you, through the team, and back with an answer. The whole team collaborates to ensure the answer is thorough and accurate.\n\n**How Transformers Work – Continuing the Library Analogy:**\nTransformers are the “thinking engine” inside the LLM part of our flowchart. They’re not a physical thing but a clever way the computer learns to understand and create language. Building on our library analogy, let’s see how a master librarian within this magical library expertly processes every detail of your question to craft the perfect response.\n\n- **Cataloging words:** When you ask a question, the master librarian breaks it down into individual pieces (like words) and organizes each piece into a detailed catalog card that holds its meaning.\n- **Tracking the order:** They also note the order of these pieces (knowing “dog chases cat” differs from “cat chases dog”) by labeling each card with its position in the sequence.\n- **Linking ideas:** The librarian examines every catalog card and connects related ideas, no matter how far apart they are. For example, in “The big dog barked,” they link “big” to “dog” to clarify it’s not a small dog, ignoring unrelated words in between.\n- **Analyzing from multiple angles:** They review the question from different perspectives simultaneously—one for overall meaning, another for how words connect—ensuring no detail is overlooked.\n- **Crafting the response:** Piece by piece, the librarian builds the answer, always checking the full set of cards to make sure each new word fits perfectly, like assembling a puzzle with precision.\n- **Delivering the answer:** Finally, they put all the pieces together into a clear, well-organized response and share it with you in simple terms.\n\nThis library magic happens incredibly fast inside the computer, allowing it to chat with you, write content, or answer nearly any question by understanding language in a human-like way. That’s the power of transformers—they enable AI to communicate with us naturally.\n\nNow that we\u0026#39;ve covered the basics, let\u0026#39;s dive deeper into the technical components that power the LLM process. Think of these as the behind-the-scenes machinery in our magical library, working together to answer your questions with precision.\n\n---\n\n## Component Spotlights: Key Elements of the LLM Process\n\n### User Input\n\nUsers interact with the LLM by providing prompts in natural language.  \n\n- **Tokenization**: The system breaks the input into *tokens*, mapping words, subwords, or characters to unique integers. This is essential, as LLMs can only work with numbers, not raw text.\n- **Example**: The phrase \u0026#34;LLMs are amazing!\u0026#34; could be tokenized as [18472, 44, 3256, 29991].\n- **Purpose**: These token IDs are then used as the starting point of the deep learning process.\n\n### RAG (Retrieval-Augmented Generation)\n\nWhen extra knowledge is needed beyond the LLM\u0026#39;s training, *RAG* augments the prompt:\n\n- **Embedding the query**: The user’s tokenized input is transformed into dense *vectors* (*embeddings*) that encapsulate semantic meaning.\n- **Semantic retrieval**: The embedding is used to semantically match relevant documents or facts from large knowledge stores, not just by word overlap but by meaning.\n- **Context addition**: The retrieved knowledge snippets are tokenized and embedded, then added to the context for the LLM to use during reasoning.\n\n### Vector DB\n\nThe *vector database* powers semantic search:\n\n- **Storing embeddings**: It contains vast collections of knowledge, each item pre-embedded into *vectors*.\n- **Similarity search**: When a query comes in, it is embedded and the DB rapidly finds vectors (documents/facts) that are closest in meaning to the query.\n- **Contextual injection**: The most relevant chunks are provided as *tokens* and *embeddings* for the LLM to attend to.\n\n### MCP Server\n\nFor live, dynamic, or specialized data, the system calls the *MCP Server*:\n\n- **Access provision**: Provides access to tools (*APIs*, calculators, real-time data sources) or proprietary datasets not within the standard training or vector DB.\n- **Data processing**: These results are processed—tokenized and embedded—and then injected into the token stream/context considered by the LLM, offering real-time augmentation.\n\n### LLM (Large Language Model)\n\nThe heart of the system runs on *transformer architecture*:\n\n- **Embeddings**: All tokens from user input, contextual passages (RAG/VectorDB), and MCP tools are turned into *embeddings*—numerical vectors that encapsulate meaning.\n- **Positional encoding**: Since transformers process input in parallel and are position-agnostic by nature, *positional encodings* are added to preserve the order of tokens, so the model knows \u0026#34;who came before whom\u0026#34;.\n- **Transformer attention**: Core innovation—*attention mechanisms* let the model weigh and relate every token in the sequence to every other for each new output token, identifying which facts or passages are most relevant at every step.\n- **Autoregressive generation**: At each inference step, the LLM predicts the next token based on all previously seen tokens and context—building up the output, token by token.\n- **Chain of Thought (CoT) prompting**: A technique called *Chain of Thought prompting* can be applied within this processing stage. CoT involves structuring the input prompt or guiding the model to articulate its reasoning process step-by-step before providing a final answer. This method is particularly useful for complex tasks requiring logical deduction, mathematical reasoning, or multi-step problem-solving.\n  - **Example**: When faced with a math problem, the model might be prompted to \u0026#34;think aloud\u0026#34; by breaking down the problem into smaller parts, solving each part, and then combining the results.\n  - **Benefit**: CoT enhances transparency and often improves accuracy by mimicking human-like reasoning patterns. It is typically integrated during the input formulation (as part of the User Input stage) or as a strategy within the LLM\u0026#39;s internal processing to structure the generation of tokens in a logical sequence.\n\n### Output\n\nThe LLM produces its final prediction:\n\n- **Outcome**: The result is a sequence of predicted *tokens*, which are then mapped back to human-readable text via *detokenization*.\n- **Impact**: This process empowers LLMs to generate highly contextual, relevant, and coherent responses—grounded in user input, retrieved/contextual documents, external knowledge, and deep language modeling.\n\n---\n\n## LLM landscape: Comparing leading models\n\n| Model                | Creator                    | Number of Parameters    | Key Characteristics / Strengths                                          |\n|----------------------|---------------------------|------------------------|--------------------------------------------------------------------------|\n| GPT-3                | OpenAI                    | 175B                   | General-purpose, pioneered language generation at scale.                 |\n| GPT-4                | OpenAI                    | ~1T (est. 500B+)       | Multimodal (text/image), improved accuracy, creative, steerable.         |\n| PaLM 2               | Google                    | 340B                   | Excels in logic, coding, multilingual understanding.                     |\n| Gemini (Pro/Ultra)   | Google                    | Up to ~1.56T (Ultra)** | Multimodal, advanced reasoning and search integration.                   |\n| LLaMA 2              | Meta (Facebook)           | 7B – 70B               | Fast, open, efficient, widely used for research and customization.       |\n| Claude 2/Opus        | Anthropic                 | ~52B+ (Claude 2), ? Opus| Aligned for safety, very long context windows (200k+ tokens).            |\n| Falcon               | TII (Abu Dhabi)           | 40B – 180B             | Open-source, highly efficient, strong at benchmarks.                     |\n| MPT                  | MosaicML                  | 7B – 30B               | Modular, commercial-use, stable for production.                          |\n| BLOOM                | BigScience org.           | 176B                   | Multilingual, collaborative open-science.                                |\n| Perplexity LLM/PPLX  | Perplexity AI             | 70B (“PPLX-70B”)       | Open-source, strong for web-augmented QA and fast API search.            |\n\n**Note**: Some parameter numbers for new or proprietary models, such as Gemini and Claude Opus, are estimates from public reporting or have not been fully disclosed.\n\n- GPT-3/4 (OpenAI): Lead in general-purpose performance, creativity, and ecosystem support.\n- PaLM 2 \u0026amp; Gemini (Google): Advanced logic, coding, real-time and search grounding.\n- LLaMA 2 (Meta): Efficient, easy to fine-tune, widely adopted.\n- Claude 2/Opus (Anthropic): Long context handling, safety and truthful dialogue focus.\n- Falcon (TII): Efficient and accessible for research/production.\n- MPT (MosaicML): Modular, stable, business-friendly licensing and support.\n- BLOOM (BigScience): Open, multilingual, global collaborative model.\n- Perplexity LLM: QA-focused, practical for information retrieval, lightweight, strong for web search tasks.\n\n---\n\n## Deep dive: How transformer architecture powers AI\n\nTransformers are the foundation of modern LLMs, introduced in the seminal paper [Attention is All You Need (2017)](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf). They revolutionized natural language processing by replacing sequential processing (like in older models such as Recurrent Neural Networks (RNNs) or Long Short-Term Memory networks (LSTMs)) with **parallel processing**, leveraging **attention mechanisms** to model relationships between words, no matter how far apart they are in a sentence. This section expands on concepts from [\u0026#34;How Transformers Architecture Works\u0026#34;](https://blog.bytebytego.com/i/163736711/how-transformers-architecture-works) to provide a deeper understanding.\n\n**Core Structure and Workflow:**\nTransformers consist of an *Encoder* and a *Decoder*, each made up of multiple layers. The encoder processes the input sequence, while the decoder generates the output sequence. In many LLMs, especially *autoregressive models* like GPT, often only the decoder part is used for tasks like text generation.\n\n- **Token embeddings**: Each input *token* (word or subword) is converted into a high-dimensional vector (e.g., 512 or 768 dimensions) that captures its semantic meaning. Think of this as translating words into a \u0026#34;language\u0026#34; of numbers that a computer can understand.\n- **Positional encoding**: Since transformers process all tokens simultaneously (not sequentially), they add *positional information* to embeddings to indicate the order of words in a sentence. This can be a fixed sinusoidal function or learned during training, ensuring the model knows \u0026#34;where\u0026#34; each token is in the sequence.\n- **Self-attention mechanism**: The heart of transformers, *self-attention* allows each token to \u0026#34;look at\u0026#34; every other token in the input to determine its relevance.\n  - **Example**: In the sentence \u0026#34;The cat, which is black, sat on the mat,\u0026#34; the word \u0026#34;cat\u0026#34; pays high attention to \u0026#34;black\u0026#34; and \u0026#34;sat\u0026#34; despite their distance.\n  - **Method**: This is computed using *Query*, *Key*, and *Value* matrices derived from the embeddings.\n- **Multi-head attention**: Instead of a single attention mechanism, transformers use multiple \u0026#34;*heads*\u0026#34; (e.g., 8 or 12) to capture different types of relationships.\n  - One head might focus on nearby words (*syntax*), another on distant words (*semantics*), providing a richer understanding of context.\n- **Feed-forward neural networks (FFNNs)**: After attention, each token\u0026#39;s representation passes through a small *neural network* (specific to its position) to further transform and refine the data. This introduces non-linearity and helps the model learn complex patterns.\n- **Layer normalization and residual connections**: Each sub-layer (attention or FFNN) is followed by *normalization* to stabilize training and *residual connections* (adding the input back to the output) to help gradients flow through deep networks, preventing vanishing gradient issues.\n- **Stacking layers**: A transformer typically has multiple encoder/decoder *layers* (e.g., 6 to 96), each repeating attention and FFNN steps. Deeper layers capture increasingly abstract features, from local word relationships to global sentence meaning.\n- **Output prediction (Softmax layer)**: For generation tasks, the final decoder layer outputs a *probability distribution* over the vocabulary for the next token. The token with the highest probability is chosen (or sampled), and the process repeats *autoregressively* until the output is complete.\n\n**Analogy for Understanding:**\nImagine a transformer as a highly efficient librarian team:\n\n- **Token embeddings** are like translating each word of your question into a detailed index card.\n- **Positional encoding** marks each card with its position in your sentence, so order isn\u0026#39;t lost.\n- **Self-attention** is the team cross-referencing every card with every other to see which ideas connect most strongly, no matter how far apart.\n- **Multi-head attention** means different librarians focus on different connections (one on grammar, another on meaning).\n- **Feed-forward layers** are like each librarian refining their notes before passing them on.\n- **Stacking layers** is passing these notes through multiple teams, each adding deeper insight.\n- Finally, **Output prediction** is the head librarian writing the best next word based on all insights, continuing until the answer is complete.\n\n**Summary Table:**\n\n| Concept                | What it Does                                                  |\n|------------------------|--------------------------------------------------------------|\n| Token Embedding        | Converts text/tokens to numerical vectors for model input    |\n| Positional Encoding    | Encodes word order to preserve sequence context              |\n| Self-Attention         | Links each token to all others based on relevance            |\n| Multi-Head Attention   | Captures multiple relationship types via parallel attention  |\n| Feed-Forward Layer     | Refines each token’s representation with non-linear changes  |\n| Layer Normalization    | Stabilizes training by normalizing layer outputs             |\n| Residual Connections   | Adds input to output to help training deep networks          |\n| Layer Stacking         | Builds depth for complex understanding across many layers    |\n| Output Prediction      | Computes the next token/word for human-like language output  |\n\nTransformers’ ability to parallelize processing, scale to billions of parameters, and focus on contextual relationships through attention makes them exceptionally powerful for language understanding and generation, powering today’s most advanced LLMs.\n\n**Key Takeaway**: Transformers are the heart of modern AI language systems, enabling them to understand context and generate human-like responses by processing words in parallel and focusing on what matters most in a sentence.\n\n---\n\n## Agentic systems and automated workflows\n\nAs Generative AI continues to evolve, two significant advancements—Automated Workflows and Agentic AI—have emerged, pushing the boundaries of what AI systems can achieve. These developments represent a shift from passive response generation to proactive, autonomous, and systematic interaction with users and environments, reflecting a sequential progression in AI capabilities.\n\n**Automated workflows: Streamlining processes with AI**\nAutomated Workflows represent an early yet powerful step in embedding AI into structured, repeatable processes to boost efficiency across various fields. This innovation automates tasks that once needed human oversight, evolving from basic rule-based systems to leveraging AI\u0026#39;s generative and reasoning strengths. Key aspects include:\n\n- **Task automation**:\n  - Early workflows handled simple tasks like scheduling or data entry.\n  - With AI, they now draft documents, generate reports, or create content using predefined templates or triggers, minimizing manual work.\n  - Example: A workflow can auto-generate a monthly sales report by pulling data (via MCP Server or Vector DB), analyzing it with the LLM, and formatting the output.\n- **Decision support**:\n  - These workflows embed decision-making logic, using AI to assess options and propose actions.\n  - They align with the \u0026#34;RAG\u0026#34; and \u0026#34;LLM\u0026#34; stages of our flowchart, retrieving and processing external data to guide decisions.\n- **Integration with systems**:\n  - Workflows link AI with business tools (like CRMs, ERPs) to manage complete processes.\n  - Example: Resolving customer support tickets by handling user input, fetching relevant data, crafting a response, and updating the system.\n\nAutomated Workflows mark a crucial evolution, shifting AI from standalone tasks to systemic integration, becoming a vital component of operational pipelines and enhancing productivity and consistency.\n\n**Agentic AI: Autonomous decision-making agents**\nBuilding on automated systems, Agentic AI marks a cutting-edge advancement where AI operates as autonomous agents, making decisions, taking actions, and pursuing goals with minimal human input. Unlike traditional Generative AI or automated workflows that react to predefined triggers, Agentic AI stands out with its proactive nature. Key capabilities include:\n\n- **Set goals and plan**:\n  - These systems define objectives based on user input or environmental context.\n  - They craft step-by-step plans to achieve goals independently.\n  - Example: An Agentic AI could plan a travel itinerary by researching destinations, booking flights, and suggesting activities—all without needing detailed human guidance.\n- **Interact with tools and environments**:\n  - Agentic AI connects with external tools, APIs, and systems (similar to the MCP Server in our workflow).\n  - It performs tasks like sending emails, updating databases, or controlling smart devices.\n- **Adapt and learn**:\n  - Through ongoing interaction and feedback, it refines strategies.\n  - It learns from successes and setbacks to enhance future performance.\n\nWithin our flowchart, Agentic AI goes beyond the \u0026#34;LLM\u0026#34; and \u0026#34;Output\u0026#34; stages, looping back to \u0026#34;User Input\u0026#34; or other components as needed to handle multi-step tasks autonomously. This evolution transforms AI from a mere responder or workflow element into a proactive partner, adept at managing complex, multi-turn interactions or projects.\n\n**Evolution of Generative AI with Automated Workflows and Agentic AI**\nThe progression of Generative AI can be seen as a sequential journey from basic automation and text generation to sophisticated, goal-oriented, and autonomous systems:\n\n- **Early Stage - Automation and Basic Tools:** Before advanced AI, automation relied on rule-based systems and simple scripts for repetitive tasks, setting the stage for integrating intelligence into workflows.\n- **Content Generation with Generative AI:** Early Generative AI models, such as GPT-2, focused on producing text or media based on prompts, mainly operating at the \u0026#34;LLM\u0026#34; and \u0026#34;Output\u0026#34; stages of our workflow.\n- **Contextual Enhancement:** With techniques like RAG and Vector DB, AI evolved to incorporate external knowledge, making responses more informed and relevant—a significant step in handling real-world queries.\n- **Systemic Integration (Automated Workflows):** Automated Workflows integrate Generative AI into broader operational frameworks, automating multi-step processes and linking all parts of our flowchart (from Input to Output) into streamlined, efficient systems, building on earlier automation concepts.\n- **Autonomous Interaction (Agentic AI):** The emergence of Agentic AI represents a significant shift towards autonomy, where AI systems proactively manage tasks, make decisions, and interact with environments, transforming the traditional workflow into adaptive, self-directed cycles.\n\nTogether, Automated Workflows and Agentic AI represent critical milestones in the evolution of Generative AI, transforming it from a tool for creation into a partner for action and automation. They build on the foundational capabilities of LLMs, enhancing their practical utility in personal, professional, and industrial contexts, with workflows providing the structure and Agentic AI adding the autonomy.\n\n---\n\n## Conclusion: Exploring AI\u0026#39;s impact\n\nAs you\u0026#39;ve seen, the journey of an LLM from understanding your input to crafting a response is a complex yet fascinating process. These systems are transforming how we interact with technology, from personal assistants to professional tools.\n\n## Glossary of key terms\n\nTo help clarify some of the technical concepts discussed, here are brief definitions of important terms used throughout this document:\n\n- **Tokenization**: The process of breaking down text into smaller units (tokens, like words or subwords) and converting them into numbers for the AI to process.\n- **Embeddings**: Numerical representations of words or phrases that capture their meaning, allowing AI to understand relationships between them.\n- **Positional Encoding**: A method to add information about the order of words in a sentence, since transformers process all words simultaneously and need to know their sequence.\n- **Self-Attention**: A mechanism that lets the AI focus on relevant words in a sentence by weighing their importance to each other, regardless of their position.\n- **Autoregressive Generation**: A technique where the AI predicts the next word (or token) based on all previously generated words, building sentences step by step.\n- **RAG (Retrieval-Augmented Generation)**: A method where AI retrieves relevant external information to enhance its responses beyond its trained knowledge.\n\n## References\n\nThis document draws inspiration and technical insights from the following sources:\n\n- [How LLMs see the world](https://blog.bytebytego.com/p/how-llms-see-the-world?utm_source=publication-search) - Provides detailed explanations on tokens, embeddings, positioning, and transformer mechanics.\n- [How Transformers Architecture Works](https://blog.bytebytego.com/i/163736711/how-transformers-architecture-works) - Offers an in-depth look at the transformer architecture that powers modern LLMs.\n- [Attention is All You Need (2017)](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) - Introduces the transformer model and attention mechanisms fundamental to modern LLMs.\n\u003c/code\u003e\u003c/pre\u003e","description":"","image":null,"permalink":"https://www.chandraharsha111.com/posts/exploring-ai-and-llms/","title":""},{"content":"\u003ch1 id=\"blogs-and-websites\"\u003eBlogs and Websites\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://jimfawcett.github.io/JimFawcett.html\"\u003eDr Fawcett\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.cis.syr.edu/~wedu/\"\u003eDr KevinDu\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://cleancoder.com/products\"\u003eBob Martin\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://martinfowler.com/\"\u003eMartin Flower\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"basic-introduction-videos\"\u003eBasic Introduction Videos\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=FZR0rG3HKIk\u0026amp;list=PLOspHqNVtKAC-_ZAGresP-i0okHe5FjcJ\u0026amp;index=7\"\u003eVirtualization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=2vMEQ5zs1ko\"\u003eKubernetes Vs Docker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=cjXI-yxqGTI\u0026amp;list=PLOspHqNVtKAC-_ZAGresP-i0okHe5FjcJ\"\u003eContainers Vs VM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=CdBtNQZH8a4\"\u003eMicroservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=fp9_ubiKqFU\u0026amp;list=PLOspHqNVtKAC-_ZAGresP-i0okHe5FjcJ\u0026amp;index=5\"\u003eCloud Native\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=HRfR4dJoKDc\u0026amp;list=PLOspHqNVtKAC-_ZAGresP-i0okHe5FjcJ\u0026amp;index=14\"\u003eBig data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=HRfR4dJoKDc\u0026amp;list=PLOspHqNVtKAC-_ZAGresP-i0okHe5FjcJ\u0026amp;index=14\"\u003eKafka\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=fy8SHvNZGeE\"\u003eHelm\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=1er2cjUq1UI\u0026amp;list=RDCMUCKWaEZ-_VweaEx1j62do_vQ\u0026amp;start_radio=1\u0026amp;t=6\"\u003eContinuous Integration\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"technologies\"\u003eTechnologies\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://dzone.com/articles/top-20-git-commands-with-examples\"\u003eGit commands\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://swagger.io/solutions/getting-started-with-oas/\"\u003eAPI best practices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://swagger.io/docs/specification/about/\"\u003eSwagger\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.jenkins.io/doc/book/pipeline/\"\u003eJenkins\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://dzone.com/articles/aws-basics\"\u003eaws-basics-dzone\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/\"\u003eSidecar\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.tutorialspoint.com/unix/unix-what-is-shell.htm\"\u003eShell scripting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://curl.se/docs/httpscripting.html\"\u003ecurl\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://developer.okta.com/blog/2017/06/21/what-the-heck-is-oauth\"\u003eoAuth1 and OAuth2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction\"\u003eDOM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://eloquentjavascript.net/\"\u003eEloquent JS Book\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ecs.syr.edu/faculty/fawcett/handouts/CSE775/Presentations/JavaScriptDemos/JavaScriptInBrowser.pdf\"\u003eJS in browser\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/A_re-introduction_to_JavaScript\"\u003eIntro to JavaScript\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"design-principles\"\u003eDesign Principles\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://ecs.syr.edu/faculty/fawcett/handouts/webpages/BlogPrinciples.htm\"\u003eSOLID principles\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ecs.syr.edu/faculty/fawcett/handouts/webpages/BlogOOD.htm\"\u003eObject Oriented design\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ecs.syr.edu/faculty/fawcett/handouts/webpages/BlogObjectModels.htm\"\u003eObject Models\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"kubernetes-docker-spinakker-helm\"\u003eKubernetes, docker, Spinakker, Helm:\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://docs.docker.com/get-started/\"\u003eDocker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/docs/home/\"\u003eKubernetes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/docs/reference/kubectl/overview/\"\u003eKubectl\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://v1-18.docs.kubernetes.io/docs/tasks/tools/install-minikube/\"\u003eMiniKube\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spinnaker.io/docs/guides/tutorials/videos/\"\u003eSpinakker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://helm.sh/\"\u003eHelmCharts\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://learn.newrelic.com/get-started-with-apm\"\u003eNewRelic\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"ruby\"\u003eRuby\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=Dji9ALCgfpM\"\u003eRuby basics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.javatpoint.com/ruby-tutorial\"\u003eRuby tutorial\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.learnrubyonline.org/en/Welcome\"\u003eRuby online org\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.tutorialspoint.com/ruby/index.htm\"\u003eTutorials point\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"dev-resources\"\u003eDev Resources\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/BurntSushi/ripgrep\"\u003eRipgrep\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://brew.sh/\"\u003eBrew\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://gceasy.io/\"\u003eHeap Analysis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://gohugo.io/hosting-and-deployment/hosting-on-github/\"\u003eHost Hugo on GitHub\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ohmyz.sh/#install\"\u003eOh-my-zsh\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","description":"","image":null,"permalink":"https://www.chandraharsha111.com/posts/software-development-resources/","title":"Software Development Resources"},{"content":"\u003ch1 id=\"books\"\u003eBooks\u003c/h1\u003e\n\u003ch3 id=\"investing\"\u003eInvesting\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/One-Up-Wall-Street-Already/dp/0743200403\"\u003eOne up on WallStreet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Beating-Street-Peter-Lynch/dp/0671891634\"\u003eBeating the street\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Intelligent-Investor-Definitive-Investing-Essentials/dp/0060555661\"\u003eIntelligent Investor\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Common-Stocks-Uncommon-Profits-Writings/dp/0471445509\"\u003eCommon Stocks and Uncommon Profits\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Principles-Life-Work-Ray-Dalio/dp/1501124021\"\u003ePrinciples RayDalio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Business-Adventures-Twelve-Classic-Street/dp/1497644895\"\u003eBusiness Adventures\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Dhandho-Investor-Low-Risk-Method-Returns/dp/047004389X\"\u003eDhandho Investor\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Buffett-American-Capitalist-Roger-Lowenstein/dp/0812979273\"\u003eMaking of American Capitalist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Payback-Time-Making-Money-Revenge/dp/0307461866\"\u003ePayback time\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Invested-Warren-Buffett-Charlie-Emotions/dp/0062672657\"\u003eInvested\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Random-Walk-Down-Wall-Street/dp/0393330338\"\u003eRandom Walk down Wall Street\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Little-Book-Common-Sense-Investing/dp/0470102101\"\u003eLittle book of common sense Investing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Wealth-Nations-Adam-Smith/dp/1505577128\"\u003eWealth of Nations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Value-Investing-Graham-Buffett-Beyond/dp/0471463396\"\u003eValue Investing from Graham to Buffet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/The_Great_Crash,_1929\"\u003eGreat crash of 1929\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://igyfoundation.org.uk/wp-content/uploads/2021/03/Full_Collection_Nomad_Letters_.pdf\"\u003eNick sleep letters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.collaborativefund.com/blog/the-psychology-of-money/\"\u003ePsychology of money\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/100-Stock-Market-Distinguished-Opportunities/dp/1626540292\"\u003e100 to 1 in the stock market\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Margin-Safety-Risk-Averse-Strategies-Thoughtful/dp/0887305105\"\u003eMargin of Safety\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Stress-Test-Reflections-Financial-Crises/dp/0804138613\"\u003eStress Test\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.goodreads.com/book/show/13586932-the-outsiders\"\u003eOutsiders\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.williamgreenwrites.com/richer-wiser-happier/\"\u003eRicher Wiser Happier\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"biographies\"\u003eBiographies\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/The_Snowball:_Warren_Buffett_and_the_Business_of_Life\"\u003eThe Snowball\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Ride-Lifetime-Lessons-Learned-Company/dp/0399592091\"\u003eRide of a lifetime\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Poor-Charlies-Almanack-Charles-Expanded/dp/1578645018\"\u003ePoor Charlies Almanack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Titan-Life-John-Rockefeller-Sr/dp/1400077303\"\u003eTitan\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"history\"\u003eHistory\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Sapiens-Humankind-Yuval-Noah-Harari/dp/0062316095\"\u003eSapiens\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Homo-Deus-Brief-History-Tomorrow/dp/0062464310\"\u003eHomo Deus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Lessons-21st-Century-Yuval-Harari/dp/0525512179\"\u003e21 lessons for 21st century\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.goodreads.com/book/show/1842.Guns_Germs_and_Steel\"\u003eGuns Germs and Steel\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"investors\"\u003eInvestors\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=S9HgIGzOENA\"\u003eCharlie Munger\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=NwwUb_QoF18\"\u003eWarren Buffer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=y3c2PKupiu8\"\u003eLi Lu\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=E_nWM4vjgqE\"\u003eMonish Pobrai\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=K-vW9ByuXTE\"\u003eLauren Templeton\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=3uJbHREmUs4\"\u003eJohn Boggle\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"interesting-websites-and-blogs\"\u003eInteresting websites and blogs\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://economicprinciples.org/\"\u003eEconomic Principles Ray Dalio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.oaktreecapital.com/insights/howard-marks-memos\"\u003eHoward Marks memos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.chaiwithpabrai.com/\"\u003eMonish Pobrai\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://people.stern.nyu.edu/adamodar/New_Home_Page/home.htm\"\u003eAshwathDamodaran\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.ruleoneinvesting.com/\"\u003ePhil Town\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.dataroma.com/m/home.php\"\u003eDataroma\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.valueline.com/\"\u003eValue Line\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.magicformulainvesting.com/\"\u003eMagic Formula\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.gatesnotes.com\"\u003eGates Notes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.gapminder.org\"\u003eGap Minder\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://usafacts.org\"\u003eUSA facts\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","description":"","image":null,"permalink":"https://www.chandraharsha111.com/posts/intesting-investing-resources/","title":"Random Interests"},{"content":"\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003eBird in the hand is worth two in the bush - Aesop 600BC\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eInvesting can simply be put as a process in which upon \u003cem\u003ethorough\u003c/em\u003e analysis, promises safety of principal and adequate return. For anyone looking into investing understanding available categories, before thinking about available choices within those categories could help with rate of return expectations. Broadly speaking I think most investors have these following options available with them\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCommodities\u003c/li\u003e\n\u003cli\u003eCurrency Denominated Investments\u003c/li\u003e\n\u003cli\u003eProductive Assets\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eCommodities\u003c/strong\u003e: \u003cem\u003eGold, Silver, Oil, Cotton\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eThis category relates to items that don\u0026rsquo;t produce anything but we expect that someone will pay us more later on. One of such  examples is Gold. If we consider all of the Gold in the world, its about 7.5 trillion. That accounts to owning total farmland in the United States(2.7 trillion) + 14 percent of all the stocks in the USA  + 1 trillion of walking money or cash in ones pocket. Choose productive assets over unproductive assets are inevitably beneficial.\u003c/p\u003e\n\u003cp\u003eGold may be a decent inflation hedge, however you could be speculating(hoping that other people will more tomorrow for the asset we hold). \u003ca href=\"https://en.wikipedia.org/wiki/John_Maynard_Keynes\"\u003eKeynes\u003c/a\u003e described it as \u0026ldquo;picking what you think that other people would pick in a beauty contest rather than picking the most beautiful women among the group\u0026rdquo;.\u003c/p\u003e\n\u003cp\u003eOther commodities like oil and cotton certainly have utility for humans. For investors, commodities can be an important way to diversify their portfolio beyond traditional securities.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCurrency Denominated Investments\u003c/strong\u003e - \u003cem\u003eBonds, Money market funds, Bank deposits, Cash\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eAlmost all of the major currencies have declined in value over time with inflation. So unless we are getting paid extremely well for having them, holding this class of investments do not make much sense. Mostly this asset class produces lower returns with lower risk, for example bank deposit. But, \u003cem\u003eits not the case always\u003c/em\u003e as in \u003ca href=\"https://www.investopedia.com/terms/d/deflation.asp\"\u003edeflationary\u003c/a\u003e periods.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eProductive assets\u003c/strong\u003e - \u003cem\u003eFarm land, Business, House\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eIn this category, we decide how much to pay for an asset based on what the asset itself will produce. For example when we buy an acre of land, we expect the farm to produce certain average yield over a period of few years.  There can be some years where the owner could be affected by drought etc, there will be some great years where the yields would be decent(based on several factors like better farming equipment or infrastructure etc). Investors can roughly calculate maintenance costs, taxes etc to determine the cash the farm can deliver to the owner. Our job as an investor is take this into account and pay a fair price for a successful investment.\u003c/p\u003e\n\u003cp\u003eWhen investing in stocks having this approach of looking at what the business does few years from now can help investors to be rational in mindset. Owning productive assets such as stocks(ownership in a piece of business) generally results in greater returns over the other two categories historically.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eInvestors can be classified as the following based on the amount of time they have to look for investment opportunities. \n   - Active Investors\n   - Passive Investors\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eActive Investing\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eIt refers to an investment strategy that involves ongoing buying of stocks or businesses upon thorough analysis, monitoring its growth prospects to exploit decent profits. An active investor will have to sell his investments even at a loss when expectations for the business change. Examples include companies like \u003ca href=\"https://www.reuters.com/article/us-berkshire-buffett-failure/buffett-calls-dexter-shoe-his-worst-deal-ever-idUSN2921504820080301\"\u003eDexter Shoes\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003eAccounting is the language of business, so I expect active investors to be well versed with it. \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://www.investopedia.com/terms/a/activeinvesting.asp\"\u003eActive investing\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePassive Investing\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eFor someone that is not having significant amount of time, Index investing provides the simplicity these investors need.  Moreover, it is self cleansing, by which I mean companies can be added and removed from the index based on business performance at a very low fee. Looking at history, I feel this is what most people should focus on and just move on with things that they are interested about in life.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.investopedia.com/terms/i/index-investing.asp\"\u003eIndex Investing\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eI believe investing is too important for most people to ignore since it has the power to change peoples lives.\u003c/p\u003e\n","description":"","image":null,"permalink":"https://www.chandraharsha111.com/posts/thoughts-on-investing/","title":"Thoughts on Investing"},{"content":"\u003ch3 id=\"group-notifier-android-app-java-php-restful-api-json-firebase\"\u003e\u003ca href=\"https://github.com/chandraharsha111/Group-Notifier-Android-App\"\u003eGroup Notifier Android App\u003c/a\u003e [Java, PHP, Restful API, JSON, Firebase]\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCreated a user-friendly app that helps users in a group to share deadlines and notify team members about events\u003c/li\u003e\n\u003cli\u003eWorked with Google API, Google Maps, Voice to text API, YouTube API, Async Tasks, Animations (Toxic Bakery)\u003c/li\u003e\n\u003cli\u003eUtilized Firebase Cloud to authenticate users and stored group information in JSON format in Firebase\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"remote-code-publisher-c-wpf-visual-studio\"\u003e\u003ca href=\"https://github.com/chandraharsha111/Remote-Code-Publisher\"\u003eRemote Code Publisher\u003c/a\u003e [C++, WPF, Visual Studio]\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDevised an application Remote Code Publisher that converts source code as web pages with embedded child\nlinks. Each link refers to a code file that the displayed code file depends on.\u003c/li\u003e\n\u003cli\u003eUsed C++ CLI shim so that WPF GUI could interact with backend (native C++). Developed a message-passing\ncommunication system, based on Sockets, using HTTP Protocol to establish communication\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"remote-test-harness-c-wcf-wpf-xml-visual-studio\"\u003e\u003ca href=\"https://github.com/chandraharsha111/Remote-Test-Harness\"\u003eRemote Test Harness\u003c/a\u003e [C#, WCF, WPF, XML, Visual Studio]\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eDeveloped Client Server based testing application which takes multiple test requests from multiple clients\u003c/li\u003e\n\u003cli\u003eImplemented Test Harness Server and Repository Server which can be queried for test result’s\u003c/li\u003e\n\u003cli\u003eEstablished remote access capabilities using WCF, developed GUI for client using WPF\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"yelp-camp-html-css-javascript-jquery-bootstrap-nodejs-express-mongodb\"\u003e\u003ca href=\"https://github.com/chandraharsha111/YelpCamp\"\u003eYelp Camp\u003c/a\u003e [HTML, CSS, JavaScript, jQuery, Bootstrap, NodeJS, Express, MongoDB]\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003eDeployed an application where users can Create, Read, Update and Delete details of camping spots they have visited\u003c/li\u003e\n\u003cli\u003eImplemented user authentication, RESTful routes, Flash messages using MEAN stack\u003c/li\u003e\n\u003c/ul\u003e\n","description":null,"image":null,"permalink":"https://www.chandraharsha111.com/projects/","title":"Projects"},{"content":"\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e \u003cspan style=\"color:#ae81ff\"\u003eGood Judgement comes from experience and experience comes from bad judgemement - Jim Horning\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"software-development-experience\"\u003eSoftware Development Experience\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eOracle  Corporation, Software Engineer, Oct 2022 - Present\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eImplemented new features and collaborated on a Java based development platform to provide a consistent means\nof developing microservices and handled central cloud deployments.\u003c/li\u003e\n\u003cli\u003eManaged Java dependencies, identified, and fixed security vulnerabilities or CVEs for microservices.\u003c/li\u003e\n\u003cli\u003eWorked on a Cadence bundles feature to manage all the enterprise stack dependencies for enterprise Java services.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eCerner Corporation, Software Engineer, June 2018-Oct 2022\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eDeveloped automation scripts and functionality that facilitated shadowing and canarying micro service migrations.\u003c/li\u003e\n\u003cli\u003eImplemented Auth support for sidecar service, which takes in SRV request and casts it to HTTP, and deployed the service      using Helm to Kubernetes.\u003c/li\u003e\n\u003cli\u003eLed API reviews across micro services to eliminate redundant APIs in Millennium, an EHR product.\u003c/li\u003e\n\u003cli\u003eLeveraged Jenkins to create multibranched pipelines across several libraries to improve CI-CD.\u003c/li\u003e\n\u003cli\u003eCreated endpoints in Spring MVC to add export functionality, implemented CRUD operations using Hibernate (HQL), Implemented UI using HTML, CSS, JavaScript, jQuery Data Table API to create responsive web pages.\u003c/li\u003e\n\u003cli\u003eMentored new associates that joined between Aug 2020 to Dec 2022\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eCognizant technology solutions, 2015-2016\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eFormulated and Implemented unit tests in .Net Platform using FAKES in C# to ensure code functionality and to improve code coverage from 60 percent to 90 percent\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"education\"\u003eEducation\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eMasters degree in Computer Engineering from Syracuse University - 2018\u003c/li\u003e\n\u003cli\u003eBachelors degree in Computer Science from SRM University - 2015\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"interests\"\u003eInterests\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eSoftware Development\u003c/li\u003e\n\u003cli\u003eEconomics\u003c/li\u003e\n\u003cli\u003eHistory\u003c/li\u003e\n\u003cli\u003ePsychology\u003c/li\u003e\n\u003c/ul\u003e\n","description":null,"image":null,"permalink":"https://www.chandraharsha111.com/about/","title":"Chandra Harsha Jupalli"}]