[{"content":"\u003ch1 id=\"from-input-to-insight-exploring-ai-and-llms\"\u003eFrom Input to Insight: Exploring AI and LLMs\u003c/h1\u003e\n  \u003c!-- Inside AI Magic: Understanding LLM Processing --\u003e\n\u003cp\u003eHave you ever wondered how AI chatbots can grasp your questions and reply so effectively? This guide walks you through how they work, starting with basic ideas and moving to deeper technical insights. These chatbots backed by LLM\u0026rsquo;s processes information in a structured order, drawing on multiple sources to improve its responses. Each step below is enhanced with concepts from \u003ca href=\"https://blog.bytebytego.com/p/how-llms-see-the-world?utm_source=publication-search\"\u003eHow LLMs see the world\u003c/a\u003e, including in-depth details on tokens, embedding, positioning, and transformer mechanics.\u003c/p\u003e\n\u003ch2 id=\"table-of-contents\"\u003eTable of contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#visual-overview-of-llm-processing-flow\"\u003eOverview of LLM processing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#ai-made-simple-understanding-the-flowchart-and-transformers-with-a-library-analogy\"\u003eUnderstanding AI basics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#component-spotlights-key-elements-of-the-llm-process\"\u003eCore components of LLMs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#llm-landscape-comparing-leading-models\"\u003eExploring AI models and technology\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#agentic-systems-and-automated-workflows\"\u003eAgentic AI and workflows\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#references\"\u003eReferences\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"visual-overview-of-llm-processing-flow\"\u003eVisual overview of LLM processing flow\u003c/h2\u003e\n\u003c!-- \n```\nNote replaced two dashes to one dash -\u003e as a work around \ngraph TD\n    Input[\"User Input\"] -\u003e RAG[\"RAG\"]\n    RAG -\u003e VectorDB[\"Vector DB\"]\n    RAG -\u003e MCP[\"MCP Server\"]\n    VectorDB -\u003e LLM[\"LLM\"]\n    MCP -\u003e LLM\n    RAG -\u003e LLM\n    LLM -\u003e Output[\"Output\"]\n```\n--\u003e\n\u003cp\u003e\u003cimg src=\"LLM%20FLow%20diagram.png\" alt=\"Flow Diagram\"\u003e\u003c/p\u003e\n\u003ch2 id=\"ai-made-simple-understanding-the-flowchart-and-transformers-with-a-library-analogy\"\u003eAI made simple: Understanding the flowchart and transformers with a library analogy\u003c/h2\u003e\n\u003cp\u003eThis analogy provides a foundational understanding of AI processes. As we progress, we\u0026rsquo;ll explore the technical details behind these components.\u003c/p\u003e\n\u003cp\u003eWhether you\u0026rsquo;re new to technology or just curious, understanding how intelligent language systems like chatbots or AI assistants operate can feel a bit overwhelming at first. Let\u0026rsquo;s simplify it by breaking down the flowchart in this document and the concept of \u0026ldquo;transformers\u0026rdquo; (the core engine behind these systems) using relatable, everyday examples.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThe Flow Chart Explained – Like a Helpful Team at a Library:\u003c/strong\u003e\nOur flowchart shows the steps an AI system takes to answer your questions. Imagine you’re at a magical library where a team works together to help you:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eUser input:\u003c/strong\u003e This is you walking up to the librarian’s desk with a question, like “Tell me about dinosaurs.”\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRAG (Retrieval-Augmented Generation):\u003c/strong\u003e The head librarian doesn’t just guess the answer. They decide if they need extra books or articles to give you the best information. They send a helper to look for these resources.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eVector DB (Database):\u003c/strong\u003e This is like a super-organized shelf of books and notes where everything is sorted by topics, not just titles. The helper quickly finds books about dinosaurs by matching the “idea” of your question to the right resources, even if you didn’t use the exact words.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMCP Server:\u003c/strong\u003e Sometimes, the librarian calls a special expert—like a paleontologist—for up-to-date or unique facts about dinosaurs that aren’t in the library books.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLLM (Large Language Model):\u003c/strong\u003e Now, the head librarian gathers all the information—from their own memory, the books, and the expert—and carefully thinks about how to explain it. They craft a clear story or answer about dinosaurs.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOutput:\u003c/strong\u003e Finally, the librarian shares the answer in simple words, making it easy to understand, like “Dinosaurs were huge creatures that lived millions of years ago…”\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe arrows in the flowchart show how information moves from you, through the team, and back with an answer. The whole team collaborates to ensure the answer is thorough and accurate.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eHow Transformers Work – Continuing the Library Analogy:\u003c/strong\u003e\nTransformers are the “thinking engine” inside the LLM part of our flowchart. They’re not a physical thing but a clever way the computer learns to understand and create language. Building on our library analogy, let’s see how a master librarian within this magical library expertly processes every detail of your question to craft the perfect response.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCataloging words:\u003c/strong\u003e When you ask a question, the master librarian breaks it down into individual pieces (like words) and organizes each piece into a detailed catalog card that holds its meaning.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTracking the order:\u003c/strong\u003e They also note the order of these pieces (knowing “dog chases cat” differs from “cat chases dog”) by labeling each card with its position in the sequence.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLinking ideas:\u003c/strong\u003e The librarian examines every catalog card and connects related ideas, no matter how far apart they are. For example, in “The big dog barked,” they link “big” to “dog” to clarify it’s not a small dog, ignoring unrelated words in between.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAnalyzing from multiple angles:\u003c/strong\u003e They review the question from different perspectives simultaneously—one for overall meaning, another for how words connect—ensuring no detail is overlooked.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCrafting the response:\u003c/strong\u003e Piece by piece, the librarian builds the answer, always checking the full set of cards to make sure each new word fits perfectly, like assembling a puzzle with precision.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDelivering the answer:\u003c/strong\u003e Finally, they put all the pieces together into a clear, well-organized response and share it with you in simple terms.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis library magic happens incredibly fast inside the computer, allowing it to chat with you, write content, or answer nearly any question by understanding language in a human-like way. That’s the power of transformers—they enable AI to communicate with us naturally.\u003c/p\u003e\n\u003cp\u003eNow that we\u0026rsquo;ve covered the basics, let\u0026rsquo;s dive deeper into the technical components that power the LLM process. Think of these as the behind-the-scenes machinery in our magical library, working together to answer your questions with precision.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"component-spotlights-key-elements-of-the-llm-process\"\u003eComponent Spotlights: Key Elements of the LLM Process\u003c/h2\u003e\n\u003ch3 id=\"user-input\"\u003eUser Input\u003c/h3\u003e\n\u003cp\u003eUsers interact with the LLM by providing prompts in natural language.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTokenization\u003c/strong\u003e: The system breaks the input into \u003cem\u003etokens\u003c/em\u003e, mapping words, subwords, or characters to unique integers. This is essential, as LLMs can only work with numbers, not raw text.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExample\u003c/strong\u003e: The phrase \u0026ldquo;LLMs are amazing!\u0026rdquo; could be tokenized as [18472, 44, 3256, 29991].\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePurpose\u003c/strong\u003e: These token IDs are then used as the starting point of the deep learning process.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"rag-retrieval-augmented-generation\"\u003eRAG (Retrieval-Augmented Generation)\u003c/h3\u003e\n\u003cp\u003eWhen extra knowledge is needed beyond the LLM\u0026rsquo;s training, \u003cem\u003eRAG\u003c/em\u003e augments the prompt:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eEmbedding the query\u003c/strong\u003e: The user’s tokenized input is transformed into dense \u003cem\u003evectors\u003c/em\u003e (\u003cem\u003eembeddings\u003c/em\u003e) that encapsulate semantic meaning.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSemantic retrieval\u003c/strong\u003e: The embedding is used to semantically match relevant documents or facts from large knowledge stores, not just by word overlap but by meaning.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eContext addition\u003c/strong\u003e: The retrieved knowledge snippets are tokenized and embedded, then added to the context for the LLM to use during reasoning.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"vector-db\"\u003eVector DB\u003c/h3\u003e\n\u003cp\u003eThe \u003cem\u003evector database\u003c/em\u003e powers semantic search:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eStoring embeddings\u003c/strong\u003e: It contains vast collections of knowledge, each item pre-embedded into \u003cem\u003evectors\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSimilarity search\u003c/strong\u003e: When a query comes in, it is embedded and the DB rapidly finds vectors (documents/facts) that are closest in meaning to the query.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eContextual injection\u003c/strong\u003e: The most relevant chunks are provided as \u003cem\u003etokens\u003c/em\u003e and \u003cem\u003eembeddings\u003c/em\u003e for the LLM to attend to.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"mcp-server\"\u003eMCP Server\u003c/h3\u003e\n\u003cp\u003eFor live, dynamic, or specialized data, the system calls the \u003cem\u003eMCP Server\u003c/em\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAccess provision\u003c/strong\u003e: Provides access to tools (\u003cem\u003eAPIs\u003c/em\u003e, calculators, real-time data sources) or proprietary datasets not within the standard training or vector DB.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eData processing\u003c/strong\u003e: These results are processed—tokenized and embedded—and then injected into the token stream/context considered by the LLM, offering real-time augmentation.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"llm-large-language-model\"\u003eLLM (Large Language Model)\u003c/h3\u003e\n\u003cp\u003eThe heart of the system runs on \u003cem\u003etransformer architecture\u003c/em\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eEmbeddings\u003c/strong\u003e: All tokens from user input, contextual passages (RAG/VectorDB), and MCP tools are turned into \u003cem\u003eembeddings\u003c/em\u003e—numerical vectors that encapsulate meaning.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePositional encoding\u003c/strong\u003e: Since transformers process input in parallel and are position-agnostic by nature, \u003cem\u003epositional encodings\u003c/em\u003e are added to preserve the order of tokens, so the model knows \u0026ldquo;who came before whom\u0026rdquo;.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTransformer attention\u003c/strong\u003e: Core innovation—\u003cem\u003eattention mechanisms\u003c/em\u003e let the model weigh and relate every token in the sequence to every other for each new output token, identifying which facts or passages are most relevant at every step.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAutoregressive generation\u003c/strong\u003e: At each inference step, the LLM predicts the next token based on all previously seen tokens and context—building up the output, token by token.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eChain of Thought (CoT) prompting\u003c/strong\u003e: A technique called \u003cem\u003eChain of Thought prompting\u003c/em\u003e can be applied within this processing stage. CoT involves structuring the input prompt or guiding the model to articulate its reasoning process step-by-step before providing a final answer. This method is particularly useful for complex tasks requiring logical deduction, mathematical reasoning, or multi-step problem-solving.\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eExample\u003c/strong\u003e: When faced with a math problem, the model might be prompted to \u0026ldquo;think aloud\u0026rdquo; by breaking down the problem into smaller parts, solving each part, and then combining the results.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBenefit\u003c/strong\u003e: CoT enhances transparency and often improves accuracy by mimicking human-like reasoning patterns. It is typically integrated during the input formulation (as part of the User Input stage) or as a strategy within the LLM\u0026rsquo;s internal processing to structure the generation of tokens in a logical sequence.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"output\"\u003eOutput\u003c/h3\u003e\n\u003cp\u003eThe LLM produces its final prediction:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOutcome\u003c/strong\u003e: The result is a sequence of predicted \u003cem\u003etokens\u003c/em\u003e, which are then mapped back to human-readable text via \u003cem\u003edetokenization\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eImpact\u003c/strong\u003e: This process empowers LLMs to generate highly contextual, relevant, and coherent responses—grounded in user input, retrieved/contextual documents, external knowledge, and deep language modeling.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"llm-landscape-comparing-leading-models\"\u003eLLM landscape: Comparing leading models\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eModel\u003c/th\u003e\n          \u003cth\u003eCreator\u003c/th\u003e\n          \u003cth\u003eNumber of Parameters\u003c/th\u003e\n          \u003cth\u003eKey Characteristics / Strengths\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eGPT-3\u003c/td\u003e\n          \u003ctd\u003eOpenAI\u003c/td\u003e\n          \u003ctd\u003e175B\u003c/td\u003e\n          \u003ctd\u003eGeneral-purpose, pioneered language generation at scale.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eGPT-4\u003c/td\u003e\n          \u003ctd\u003eOpenAI\u003c/td\u003e\n          \u003ctd\u003e~1T (est. 500B+)\u003c/td\u003e\n          \u003ctd\u003eMultimodal (text/image), improved accuracy, creative, steerable.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ePaLM 2\u003c/td\u003e\n          \u003ctd\u003eGoogle\u003c/td\u003e\n          \u003ctd\u003e340B\u003c/td\u003e\n          \u003ctd\u003eExcels in logic, coding, multilingual understanding.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eGemini (Pro/Ultra)\u003c/td\u003e\n          \u003ctd\u003eGoogle\u003c/td\u003e\n          \u003ctd\u003eUp to ~1.56T (Ultra)**\u003c/td\u003e\n          \u003ctd\u003eMultimodal, advanced reasoning and search integration.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eLLaMA 2\u003c/td\u003e\n          \u003ctd\u003eMeta (Facebook)\u003c/td\u003e\n          \u003ctd\u003e7B – 70B\u003c/td\u003e\n          \u003ctd\u003eFast, open, efficient, widely used for research and customization.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eClaude 2/Opus\u003c/td\u003e\n          \u003ctd\u003eAnthropic\u003c/td\u003e\n          \u003ctd\u003e~52B+ (Claude 2), ? Opus\u003c/td\u003e\n          \u003ctd\u003eAligned for safety, very long context windows (200k+ tokens).\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFalcon\u003c/td\u003e\n          \u003ctd\u003eTII (Abu Dhabi)\u003c/td\u003e\n          \u003ctd\u003e40B – 180B\u003c/td\u003e\n          \u003ctd\u003eOpen-source, highly efficient, strong at benchmarks.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eMPT\u003c/td\u003e\n          \u003ctd\u003eMosaicML\u003c/td\u003e\n          \u003ctd\u003e7B – 30B\u003c/td\u003e\n          \u003ctd\u003eModular, commercial-use, stable for production.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eBLOOM\u003c/td\u003e\n          \u003ctd\u003eBigScience org.\u003c/td\u003e\n          \u003ctd\u003e176B\u003c/td\u003e\n          \u003ctd\u003eMultilingual, collaborative open-science.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ePerplexity LLM/PPLX\u003c/td\u003e\n          \u003ctd\u003ePerplexity AI\u003c/td\u003e\n          \u003ctd\u003e70B (“PPLX-70B”)\u003c/td\u003e\n          \u003ctd\u003eOpen-source, strong for web-augmented QA and fast API search.\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: Some parameter numbers for new or proprietary models, such as Gemini and Claude Opus, are estimates from public reporting or have not been fully disclosed.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGPT-3/4 (OpenAI): Lead in general-purpose performance, creativity, and ecosystem support.\u003c/li\u003e\n\u003cli\u003ePaLM 2 \u0026amp; Gemini (Google): Advanced logic, coding, real-time and search grounding.\u003c/li\u003e\n\u003cli\u003eLLaMA 2 (Meta): Efficient, easy to fine-tune, widely adopted.\u003c/li\u003e\n\u003cli\u003eClaude 2/Opus (Anthropic): Long context handling, safety and truthful dialogue focus.\u003c/li\u003e\n\u003cli\u003eFalcon (TII): Efficient and accessible for research/production.\u003c/li\u003e\n\u003cli\u003eMPT (MosaicML): Modular, stable, business-friendly licensing and support.\u003c/li\u003e\n\u003cli\u003eBLOOM (BigScience): Open, multilingual, global collaborative model.\u003c/li\u003e\n\u003cli\u003ePerplexity LLM: QA-focused, practical for information retrieval, lightweight, strong for web search tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"deep-dive-how-transformer-architecture-powers-ai\"\u003eDeep dive: How transformer architecture powers AI\u003c/h2\u003e\n\u003cp\u003eTransformers are the foundation of modern LLMs, introduced in the seminal paper \u003ca href=\"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\"\u003eAttention is All You Need (2017)\u003c/a\u003e. They revolutionized natural language processing by replacing sequential processing (like in older models such as Recurrent Neural Networks (RNNs) or Long Short-Term Memory networks (LSTMs)) with \u003cstrong\u003eparallel processing\u003c/strong\u003e, leveraging \u003cstrong\u003eattention mechanisms\u003c/strong\u003e to model relationships between words, no matter how far apart they are in a sentence. This section expands on concepts from \u003ca href=\"https://blog.bytebytego.com/i/163736711/how-transformers-architecture-works\"\u003e\u0026ldquo;How Transformers Architecture Works\u0026rdquo;\u003c/a\u003e to provide a deeper understanding.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCore Structure and Workflow:\u003c/strong\u003e\nTransformers consist of an \u003cem\u003eEncoder\u003c/em\u003e and a \u003cem\u003eDecoder\u003c/em\u003e, each made up of multiple layers. The encoder processes the input sequence, while the decoder generates the output sequence. In many LLMs, especially \u003cem\u003eautoregressive models\u003c/em\u003e like GPT, often only the decoder part is used for tasks like text generation.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eToken embeddings\u003c/strong\u003e: Each input \u003cem\u003etoken\u003c/em\u003e (word or subword) is converted into a high-dimensional vector (e.g., 512 or 768 dimensions) that captures its semantic meaning. Think of this as translating words into a \u0026ldquo;language\u0026rdquo; of numbers that a computer can understand.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePositional encoding\u003c/strong\u003e: Since transformers process all tokens simultaneously (not sequentially), they add \u003cem\u003epositional information\u003c/em\u003e to embeddings to indicate the order of words in a sentence. This can be a fixed sinusoidal function or learned during training, ensuring the model knows \u0026ldquo;where\u0026rdquo; each token is in the sequence.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSelf-attention mechanism\u003c/strong\u003e: The heart of transformers, \u003cem\u003eself-attention\u003c/em\u003e allows each token to \u0026ldquo;look at\u0026rdquo; every other token in the input to determine its relevance.\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eExample\u003c/strong\u003e: In the sentence \u0026ldquo;The cat, which is black, sat on the mat,\u0026rdquo; the word \u0026ldquo;cat\u0026rdquo; pays high attention to \u0026ldquo;black\u0026rdquo; and \u0026ldquo;sat\u0026rdquo; despite their distance.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMethod\u003c/strong\u003e: This is computed using \u003cem\u003eQuery\u003c/em\u003e, \u003cem\u003eKey\u003c/em\u003e, and \u003cem\u003eValue\u003c/em\u003e matrices derived from the embeddings.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMulti-head attention\u003c/strong\u003e: Instead of a single attention mechanism, transformers use multiple \u0026ldquo;\u003cem\u003eheads\u003c/em\u003e\u0026rdquo; (e.g., 8 or 12) to capture different types of relationships.\n\u003cul\u003e\n\u003cli\u003eOne head might focus on nearby words (\u003cem\u003esyntax\u003c/em\u003e), another on distant words (\u003cem\u003esemantics\u003c/em\u003e), providing a richer understanding of context.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFeed-forward neural networks (FFNNs)\u003c/strong\u003e: After attention, each token\u0026rsquo;s representation passes through a small \u003cem\u003eneural network\u003c/em\u003e (specific to its position) to further transform and refine the data. This introduces non-linearity and helps the model learn complex patterns.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eLayer normalization and residual connections\u003c/strong\u003e: Each sub-layer (attention or FFNN) is followed by \u003cem\u003enormalization\u003c/em\u003e to stabilize training and \u003cem\u003eresidual connections\u003c/em\u003e (adding the input back to the output) to help gradients flow through deep networks, preventing vanishing gradient issues.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStacking layers\u003c/strong\u003e: A transformer typically has multiple encoder/decoder \u003cem\u003elayers\u003c/em\u003e (e.g., 6 to 96), each repeating attention and FFNN steps. Deeper layers capture increasingly abstract features, from local word relationships to global sentence meaning.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOutput prediction (Softmax layer)\u003c/strong\u003e: For generation tasks, the final decoder layer outputs a \u003cem\u003eprobability distribution\u003c/em\u003e over the vocabulary for the next token. The token with the highest probability is chosen (or sampled), and the process repeats \u003cem\u003eautoregressively\u003c/em\u003e until the output is complete.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eAnalogy for Understanding:\u003c/strong\u003e\nImagine a transformer as a highly efficient librarian team:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eToken embeddings\u003c/strong\u003e are like translating each word of your question into a detailed index card.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePositional encoding\u003c/strong\u003e marks each card with its position in your sentence, so order isn\u0026rsquo;t lost.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSelf-attention\u003c/strong\u003e is the team cross-referencing every card with every other to see which ideas connect most strongly, no matter how far apart.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMulti-head attention\u003c/strong\u003e means different librarians focus on different connections (one on grammar, another on meaning).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFeed-forward layers\u003c/strong\u003e are like each librarian refining their notes before passing them on.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStacking layers\u003c/strong\u003e is passing these notes through multiple teams, each adding deeper insight.\u003c/li\u003e\n\u003cli\u003eFinally, \u003cstrong\u003eOutput prediction\u003c/strong\u003e is the head librarian writing the best next word based on all insights, continuing until the answer is complete.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSummary Table:\u003c/strong\u003e\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eConcept\u003c/th\u003e\n          \u003cth\u003eWhat it Does\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eToken Embedding\u003c/td\u003e\n          \u003ctd\u003eConverts text/tokens to numerical vectors for model input\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003ePositional Encoding\u003c/td\u003e\n          \u003ctd\u003eEncodes word order to preserve sequence context\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eSelf-Attention\u003c/td\u003e\n          \u003ctd\u003eLinks each token to all others based on relevance\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eMulti-Head Attention\u003c/td\u003e\n          \u003ctd\u003eCaptures multiple relationship types via parallel attention\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eFeed-Forward Layer\u003c/td\u003e\n          \u003ctd\u003eRefines each token’s representation with non-linear changes\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eLayer Normalization\u003c/td\u003e\n          \u003ctd\u003eStabilizes training by normalizing layer outputs\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eResidual Connections\u003c/td\u003e\n          \u003ctd\u003eAdds input to output to help training deep networks\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eLayer Stacking\u003c/td\u003e\n          \u003ctd\u003eBuilds depth for complex understanding across many layers\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eOutput Prediction\u003c/td\u003e\n          \u003ctd\u003eComputes the next token/word for human-like language output\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eTransformers’ ability to parallelize processing, scale to billions of parameters, and focus on contextual relationships through attention makes them exceptionally powerful for language understanding and generation, powering today’s most advanced LLMs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKey Takeaway\u003c/strong\u003e: Transformers are the heart of modern AI language systems, enabling them to understand context and generate human-like responses by processing words in parallel and focusing on what matters most in a sentence.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"agentic-systems-and-automated-workflows\"\u003eAgentic systems and automated workflows\u003c/h2\u003e\n\u003cp\u003eAs Generative AI continues to evolve, two significant advancements—Automated Workflows and Agentic AI—have emerged, pushing the boundaries of what AI systems can achieve. These developments represent a shift from passive response generation to proactive, autonomous, and systematic interaction with users and environments, reflecting a sequential progression in AI capabilities.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAutomated workflows: Streamlining processes with AI\u003c/strong\u003e\nAutomated Workflows represent an early yet powerful step in embedding AI into structured, repeatable processes to boost efficiency across various fields. This innovation automates tasks that once needed human oversight, evolving from basic rule-based systems to leveraging AI\u0026rsquo;s generative and reasoning strengths. Key aspects include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTask automation\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eEarly workflows handled simple tasks like scheduling or data entry.\u003c/li\u003e\n\u003cli\u003eWith AI, they now draft documents, generate reports, or create content using predefined templates or triggers, minimizing manual work.\u003c/li\u003e\n\u003cli\u003eExample: A workflow can auto-generate a monthly sales report by pulling data (via MCP Server or Vector DB), analyzing it with the LLM, and formatting the output.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDecision support\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eThese workflows embed decision-making logic, using AI to assess options and propose actions.\u003c/li\u003e\n\u003cli\u003eThey align with the \u0026ldquo;RAG\u0026rdquo; and \u0026ldquo;LLM\u0026rdquo; stages of our flowchart, retrieving and processing external data to guide decisions.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIntegration with systems\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eWorkflows link AI with business tools (like CRMs, ERPs) to manage complete processes.\u003c/li\u003e\n\u003cli\u003eExample: Resolving customer support tickets by handling user input, fetching relevant data, crafting a response, and updating the system.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAutomated Workflows mark a crucial evolution, shifting AI from standalone tasks to systemic integration, becoming a vital component of operational pipelines and enhancing productivity and consistency.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAgentic AI: Autonomous decision-making agents\u003c/strong\u003e\nBuilding on automated systems, Agentic AI marks a cutting-edge advancement where AI operates as autonomous agents, making decisions, taking actions, and pursuing goals with minimal human input. Unlike traditional Generative AI or automated workflows that react to predefined triggers, Agentic AI stands out with its proactive nature. Key capabilities include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSet goals and plan\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eThese systems define objectives based on user input or environmental context.\u003c/li\u003e\n\u003cli\u003eThey craft step-by-step plans to achieve goals independently.\u003c/li\u003e\n\u003cli\u003eExample: An Agentic AI could plan a travel itinerary by researching destinations, booking flights, and suggesting activities—all without needing detailed human guidance.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInteract with tools and environments\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eAgentic AI connects with external tools, APIs, and systems (similar to the MCP Server in our workflow).\u003c/li\u003e\n\u003cli\u003eIt performs tasks like sending emails, updating databases, or controlling smart devices.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAdapt and learn\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eThrough ongoing interaction and feedback, it refines strategies.\u003c/li\u003e\n\u003cli\u003eIt learns from successes and setbacks to enhance future performance.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWithin our flowchart, Agentic AI goes beyond the \u0026ldquo;LLM\u0026rdquo; and \u0026ldquo;Output\u0026rdquo; stages, looping back to \u0026ldquo;User Input\u0026rdquo; or other components as needed to handle multi-step tasks autonomously. This evolution transforms AI from a mere responder or workflow element into a proactive partner, adept at managing complex, multi-turn interactions or projects.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eEvolution of Generative AI with Automated Workflows and Agentic AI\u003c/strong\u003e\nThe progression of Generative AI can be seen as a sequential journey from basic automation and text generation to sophisticated, goal-oriented, and autonomous systems:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eEarly Stage - Automation and Basic Tools:\u003c/strong\u003e Before advanced AI, automation relied on rule-based systems and simple scripts for repetitive tasks, setting the stage for integrating intelligence into workflows.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eContent Generation with Generative AI:\u003c/strong\u003e Early Generative AI models, such as GPT-2, focused on producing text or media based on prompts, mainly operating at the \u0026ldquo;LLM\u0026rdquo; and \u0026ldquo;Output\u0026rdquo; stages of our workflow.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eContextual Enhancement:\u003c/strong\u003e With techniques like RAG and Vector DB, AI evolved to incorporate external knowledge, making responses more informed and relevant—a significant step in handling real-world queries.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSystemic Integration (Automated Workflows):\u003c/strong\u003e Automated Workflows integrate Generative AI into broader operational frameworks, automating multi-step processes and linking all parts of our flowchart (from Input to Output) into streamlined, efficient systems, building on earlier automation concepts.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAutonomous Interaction (Agentic AI):\u003c/strong\u003e The emergence of Agentic AI represents a significant shift towards autonomy, where AI systems proactively manage tasks, make decisions, and interact with environments, transforming the traditional workflow into adaptive, self-directed cycles.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTogether, Automated Workflows and Agentic AI represent critical milestones in the evolution of Generative AI, transforming it from a tool for creation into a partner for action and automation. They build on the foundational capabilities of LLMs, enhancing their practical utility in personal, professional, and industrial contexts, with workflows providing the structure and Agentic AI adding the autonomy.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"conclusion-exploring-ais-impact\"\u003eConclusion: Exploring AI\u0026rsquo;s impact\u003c/h2\u003e\n\u003cp\u003eAs you\u0026rsquo;ve seen, the journey of an LLM from understanding your input to crafting a response is a complex yet fascinating process. These systems are transforming how we interact with technology, from personal assistants to professional tools.\u003c/p\u003e\n\u003ch2 id=\"glossary-of-key-terms\"\u003eGlossary of key terms\u003c/h2\u003e\n\u003cp\u003eTo help clarify some of the technical concepts discussed, here are brief definitions of important terms used throughout this document:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTokenization\u003c/strong\u003e: The process of breaking down text into smaller units (tokens, like words or subwords) and converting them into numbers for the AI to process.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEmbeddings\u003c/strong\u003e: Numerical representations of words or phrases that capture their meaning, allowing AI to understand relationships between them.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePositional Encoding\u003c/strong\u003e: A method to add information about the order of words in a sentence, since transformers process all words simultaneously and need to know their sequence.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSelf-Attention\u003c/strong\u003e: A mechanism that lets the AI focus on relevant words in a sentence by weighing their importance to each other, regardless of their position.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAutoregressive Generation\u003c/strong\u003e: A technique where the AI predicts the next word (or token) based on all previously generated words, building sentences step by step.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRAG (Retrieval-Augmented Generation)\u003c/strong\u003e: A method where AI retrieves relevant external information to enhance its responses beyond its trained knowledge.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003cp\u003eThis document draws inspiration and technical insights from the following sources:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://blog.bytebytego.com/p/how-llms-see-the-world?utm_source=publication-search\"\u003eHow LLMs see the world\u003c/a\u003e - Provides detailed explanations on tokens, embeddings, positioning, and transformer mechanics.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://blog.bytebytego.com/i/163736711/how-transformers-architecture-works\"\u003eHow Transformers Architecture Works\u003c/a\u003e - Offers an in-depth look at the transformer architecture that powers modern LLMs.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\"\u003eAttention is All You Need (2017)\u003c/a\u003e - Introduces the transformer model and attention mechanisms fundamental to modern LLMs.\u003c/li\u003e\n\u003c/ul\u003e\n","description":"","image":null,"permalink":"https://www.chandraharsha111.com/posts/exploring-ai-and-llms/","title":""},{"content":"\u003ch1 id=\"blogs-and-websites\"\u003eBlogs and Websites\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://jimfawcett.github.io/JimFawcett.html\"\u003eDr Fawcett\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.cis.syr.edu/~wedu/\"\u003eDr KevinDu\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://cleancoder.com/products\"\u003eBob Martin\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://martinfowler.com/\"\u003eMartin Flower\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"basic-introduction-videos\"\u003eBasic Introduction Videos\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=FZR0rG3HKIk\u0026amp;list=PLOspHqNVtKAC-_ZAGresP-i0okHe5FjcJ\u0026amp;index=7\"\u003eVirtualization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=2vMEQ5zs1ko\"\u003eKubernetes Vs Docker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=cjXI-yxqGTI\u0026amp;list=PLOspHqNVtKAC-_ZAGresP-i0okHe5FjcJ\"\u003eContainers Vs VM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=CdBtNQZH8a4\"\u003eMicroservices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=fp9_ubiKqFU\u0026amp;list=PLOspHqNVtKAC-_ZAGresP-i0okHe5FjcJ\u0026amp;index=5\"\u003eCloud Native\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=HRfR4dJoKDc\u0026amp;list=PLOspHqNVtKAC-_ZAGresP-i0okHe5FjcJ\u0026amp;index=14\"\u003eBig data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=HRfR4dJoKDc\u0026amp;list=PLOspHqNVtKAC-_ZAGresP-i0okHe5FjcJ\u0026amp;index=14\"\u003eKafka\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=fy8SHvNZGeE\"\u003eHelm\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=1er2cjUq1UI\u0026amp;list=RDCMUCKWaEZ-_VweaEx1j62do_vQ\u0026amp;start_radio=1\u0026amp;t=6\"\u003eContinuous Integration\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"technologies\"\u003eTechnologies\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://dzone.com/articles/top-20-git-commands-with-examples\"\u003eGit commands\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://swagger.io/solutions/getting-started-with-oas/\"\u003eAPI best practices\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://swagger.io/docs/specification/about/\"\u003eSwagger\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.jenkins.io/doc/book/pipeline/\"\u003eJenkins\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://dzone.com/articles/aws-basics\"\u003eaws-basics-dzone\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/\"\u003eSidecar\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.tutorialspoint.com/unix/unix-what-is-shell.htm\"\u003eShell scripting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://curl.se/docs/httpscripting.html\"\u003ecurl\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://developer.okta.com/blog/2017/06/21/what-the-heck-is-oauth\"\u003eoAuth1 and OAuth2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction\"\u003eDOM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://eloquentjavascript.net/\"\u003eEloquent JS Book\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ecs.syr.edu/faculty/fawcett/handouts/CSE775/Presentations/JavaScriptDemos/JavaScriptInBrowser.pdf\"\u003eJS in browser\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/A_re-introduction_to_JavaScript\"\u003eIntro to JavaScript\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"design-principles\"\u003eDesign Principles\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://ecs.syr.edu/faculty/fawcett/handouts/webpages/BlogPrinciples.htm\"\u003eSOLID principles\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ecs.syr.edu/faculty/fawcett/handouts/webpages/BlogOOD.htm\"\u003eObject Oriented design\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ecs.syr.edu/faculty/fawcett/handouts/webpages/BlogObjectModels.htm\"\u003eObject Models\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"kubernetes-docker-spinakker-helm\"\u003eKubernetes, docker, Spinakker, Helm:\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://docs.docker.com/get-started/\"\u003eDocker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/docs/home/\"\u003eKubernetes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/docs/reference/kubectl/overview/\"\u003eKubectl\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://v1-18.docs.kubernetes.io/docs/tasks/tools/install-minikube/\"\u003eMiniKube\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spinnaker.io/docs/guides/tutorials/videos/\"\u003eSpinakker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://helm.sh/\"\u003eHelmCharts\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://learn.newrelic.com/get-started-with-apm\"\u003eNewRelic\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"ruby\"\u003eRuby\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=Dji9ALCgfpM\"\u003eRuby basics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.javatpoint.com/ruby-tutorial\"\u003eRuby tutorial\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.learnrubyonline.org/en/Welcome\"\u003eRuby online org\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.tutorialspoint.com/ruby/index.htm\"\u003eTutorials point\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"dev-resources\"\u003eDev Resources\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/BurntSushi/ripgrep\"\u003eRipgrep\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://brew.sh/\"\u003eBrew\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://gceasy.io/\"\u003eHeap Analysis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://gohugo.io/hosting-and-deployment/hosting-on-github/\"\u003eHost Hugo on GitHub\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ohmyz.sh/#install\"\u003eOh-my-zsh\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","description":"","image":null,"permalink":"https://www.chandraharsha111.com/posts/software-development-resources/","title":"Software Development Resources"},{"content":"\u003ch1 id=\"books\"\u003eBooks\u003c/h1\u003e\n\u003ch3 id=\"investing\"\u003eInvesting\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/One-Up-Wall-Street-Already/dp/0743200403\"\u003eOne up on WallStreet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Beating-Street-Peter-Lynch/dp/0671891634\"\u003eBeating the street\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Intelligent-Investor-Definitive-Investing-Essentials/dp/0060555661\"\u003eIntelligent Investor\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Common-Stocks-Uncommon-Profits-Writings/dp/0471445509\"\u003eCommon Stocks and Uncommon Profits\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Principles-Life-Work-Ray-Dalio/dp/1501124021\"\u003ePrinciples RayDalio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Business-Adventures-Twelve-Classic-Street/dp/1497644895\"\u003eBusiness Adventures\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Dhandho-Investor-Low-Risk-Method-Returns/dp/047004389X\"\u003eDhandho Investor\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Buffett-American-Capitalist-Roger-Lowenstein/dp/0812979273\"\u003eMaking of American Capitalist\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Payback-Time-Making-Money-Revenge/dp/0307461866\"\u003ePayback time\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Invested-Warren-Buffett-Charlie-Emotions/dp/0062672657\"\u003eInvested\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Random-Walk-Down-Wall-Street/dp/0393330338\"\u003eRandom Walk down Wall Street\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Little-Book-Common-Sense-Investing/dp/0470102101\"\u003eLittle book of common sense Investing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Wealth-Nations-Adam-Smith/dp/1505577128\"\u003eWealth of Nations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Value-Investing-Graham-Buffett-Beyond/dp/0471463396\"\u003eValue Investing from Graham to Buffet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/The_Great_Crash,_1929\"\u003eGreat crash of 1929\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://igyfoundation.org.uk/wp-content/uploads/2021/03/Full_Collection_Nomad_Letters_.pdf\"\u003eNick sleep letters\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.collaborativefund.com/blog/the-psychology-of-money/\"\u003ePsychology of money\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/100-Stock-Market-Distinguished-Opportunities/dp/1626540292\"\u003e100 to 1 in the stock market\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Margin-Safety-Risk-Averse-Strategies-Thoughtful/dp/0887305105\"\u003eMargin of Safety\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Stress-Test-Reflections-Financial-Crises/dp/0804138613\"\u003eStress Test\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.goodreads.com/book/show/13586932-the-outsiders\"\u003eOutsiders\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.williamgreenwrites.com/richer-wiser-happier/\"\u003eRicher Wiser Happier\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"biographies\"\u003eBiographies\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/The_Snowball:_Warren_Buffett_and_the_Business_of_Life\"\u003eThe Snowball\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Ride-Lifetime-Lessons-Learned-Company/dp/0399592091\"\u003eRide of a lifetime\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Poor-Charlies-Almanack-Charles-Expanded/dp/1578645018\"\u003ePoor Charlies Almanack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Titan-Life-John-Rockefeller-Sr/dp/1400077303\"\u003eTitan\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"history\"\u003eHistory\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Sapiens-Humankind-Yuval-Noah-Harari/dp/0062316095\"\u003eSapiens\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Homo-Deus-Brief-History-Tomorrow/dp/0062464310\"\u003eHomo Deus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Lessons-21st-Century-Yuval-Harari/dp/0525512179\"\u003e21 lessons for 21st century\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.goodreads.com/book/show/1842.Guns_Germs_and_Steel\"\u003eGuns Germs and Steel\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"investors\"\u003eInvestors\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=S9HgIGzOENA\"\u003eCharlie Munger\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=NwwUb_QoF18\"\u003eWarren Buffer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=y3c2PKupiu8\"\u003eLi Lu\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=E_nWM4vjgqE\"\u003eMonish Pobrai\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=K-vW9ByuXTE\"\u003eLauren Templeton\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=3uJbHREmUs4\"\u003eJohn Boggle\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"interesting-websites-and-blogs\"\u003eInteresting websites and blogs\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://economicprinciples.org/\"\u003eEconomic Principles Ray Dalio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.oaktreecapital.com/insights/howard-marks-memos\"\u003eHoward Marks memos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.chaiwithpabrai.com/\"\u003eMonish Pobrai\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://people.stern.nyu.edu/adamodar/New_Home_Page/home.htm\"\u003eAshwathDamodaran\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.ruleoneinvesting.com/\"\u003ePhil Town\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.dataroma.com/m/home.php\"\u003eDataroma\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.valueline.com/\"\u003eValue Line\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.magicformulainvesting.com/\"\u003eMagic Formula\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.gatesnotes.com\"\u003eGates Notes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.gapminder.org\"\u003eGap Minder\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://usafacts.org\"\u003eUSA facts\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","description":"","image":null,"permalink":"https://www.chandraharsha111.com/posts/intesting-investing-resources/","title":"Random Interests"},{"content":"\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003eBird in the hand is worth two in the bush - Aesop 600BC\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eInvesting can simply be put as a process in which upon \u003cem\u003ethorough\u003c/em\u003e analysis, promises safety of principal and adequate return. For anyone looking into investing understanding available categories, before thinking about available choices within those categories could help with rate of return expectations. Broadly speaking I think most investors have these following options available with them\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCommodities\u003c/li\u003e\n\u003cli\u003eCurrency Denominated Investments\u003c/li\u003e\n\u003cli\u003eProductive Assets\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eCommodities\u003c/strong\u003e: \u003cem\u003eGold, Silver, Oil, Cotton\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eThis category relates to items that don\u0026rsquo;t produce anything but we expect that someone will pay us more later on. One of such  examples is Gold. If we consider all of the Gold in the world, its about 7.5 trillion. That accounts to owning total farmland in the United States(2.7 trillion) + 14 percent of all the stocks in the USA  + 1 trillion of walking money or cash in ones pocket. Choose productive assets over unproductive assets are inevitably beneficial.\u003c/p\u003e\n\u003cp\u003eGold may be a decent inflation hedge, however you could be speculating(hoping that other people will more tomorrow for the asset we hold). \u003ca href=\"https://en.wikipedia.org/wiki/John_Maynard_Keynes\"\u003eKeynes\u003c/a\u003e described it as \u0026ldquo;picking what you think that other people would pick in a beauty contest rather than picking the most beautiful women among the group\u0026rdquo;.\u003c/p\u003e\n\u003cp\u003eOther commodities like oil and cotton certainly have utility for humans. For investors, commodities can be an important way to diversify their portfolio beyond traditional securities.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCurrency Denominated Investments\u003c/strong\u003e - \u003cem\u003eBonds, Money market funds, Bank deposits, Cash\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eAlmost all of the major currencies have declined in value over time with inflation. So unless we are getting paid extremely well for having them, holding this class of investments do not make much sense. Mostly this asset class produces lower returns with lower risk, for example bank deposit. But, \u003cem\u003eits not the case always\u003c/em\u003e as in \u003ca href=\"https://www.investopedia.com/terms/d/deflation.asp\"\u003edeflationary\u003c/a\u003e periods.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eProductive assets\u003c/strong\u003e - \u003cem\u003eFarm land, Business, House\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eIn this category, we decide how much to pay for an asset based on what the asset itself will produce. For example when we buy an acre of land, we expect the farm to produce certain average yield over a period of few years.  There can be some years where the owner could be affected by drought etc, there will be some great years where the yields would be decent(based on several factors like better farming equipment or infrastructure etc). Investors can roughly calculate maintenance costs, taxes etc to determine the cash the farm can deliver to the owner. Our job as an investor is take this into account and pay a fair price for a successful investment.\u003c/p\u003e\n\u003cp\u003eWhen investing in stocks having this approach of looking at what the business does few years from now can help investors to be rational in mindset. Owning productive assets such as stocks(ownership in a piece of business) generally results in greater returns over the other two categories historically.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eInvestors can be classified as the following based on the amount of time they have to look for investment opportunities. \n   - Active Investors\n   - Passive Investors\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eActive Investing\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eIt refers to an investment strategy that involves ongoing buying of stocks or businesses upon thorough analysis, monitoring its growth prospects to exploit decent profits. An active investor will have to sell his investments even at a loss when expectations for the business change. Examples include companies like \u003ca href=\"https://www.reuters.com/article/us-berkshire-buffett-failure/buffett-calls-dexter-shoe-his-worst-deal-ever-idUSN2921504820080301\"\u003eDexter Shoes\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003eAccounting is the language of business, so I expect active investors to be well versed with it. \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://www.investopedia.com/terms/a/activeinvesting.asp\"\u003eActive investing\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePassive Investing\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eFor someone that is not having significant amount of time, Index investing provides the simplicity these investors need.  Moreover, it is self cleansing, by which I mean companies can be added and removed from the index based on business performance at a very low fee. Looking at history, I feel this is what most people should focus on and just move on with things that they are interested about in life.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.investopedia.com/terms/i/index-investing.asp\"\u003eIndex Investing\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eI believe investing is too important for most people to ignore since it has the power to change peoples lives.\u003c/p\u003e\n","description":"","image":null,"permalink":"https://www.chandraharsha111.com/posts/thoughts-on-investing/","title":"Thoughts on Investing"},{"content":"\u003ch3 id=\"group-notifier-android-app-java-php-restful-api-json-firebase\"\u003e\u003ca href=\"https://github.com/chandraharsha111/Group-Notifier-Android-App\"\u003eGroup Notifier Android App\u003c/a\u003e [Java, PHP, Restful API, JSON, Firebase]\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCreated a user-friendly app that helps users in a group to share deadlines and notify team members about events\u003c/li\u003e\n\u003cli\u003eWorked with Google API, Google Maps, Voice to text API, YouTube API, Async Tasks, Animations (Toxic Bakery)\u003c/li\u003e\n\u003cli\u003eUtilized Firebase Cloud to authenticate users and stored group information in JSON format in Firebase\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"remote-code-publisher-c-wpf-visual-studio\"\u003e\u003ca href=\"https://github.com/chandraharsha111/Remote-Code-Publisher\"\u003eRemote Code Publisher\u003c/a\u003e [C++, WPF, Visual Studio]\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eDevised an application Remote Code Publisher that converts source code as web pages with embedded child\nlinks. Each link refers to a code file that the displayed code file depends on.\u003c/li\u003e\n\u003cli\u003eUsed C++ CLI shim so that WPF GUI could interact with backend (native C++). Developed a message-passing\ncommunication system, based on Sockets, using HTTP Protocol to establish communication\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"remote-test-harness-c-wcf-wpf-xml-visual-studio\"\u003e\u003ca href=\"https://github.com/chandraharsha111/Remote-Test-Harness\"\u003eRemote Test Harness\u003c/a\u003e [C#, WCF, WPF, XML, Visual Studio]\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eDeveloped Client Server based testing application which takes multiple test requests from multiple clients\u003c/li\u003e\n\u003cli\u003eImplemented Test Harness Server and Repository Server which can be queried for test result’s\u003c/li\u003e\n\u003cli\u003eEstablished remote access capabilities using WCF, developed GUI for client using WPF\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"yelp-camp-html-css-javascript-jquery-bootstrap-nodejs-express-mongodb\"\u003e\u003ca href=\"https://github.com/chandraharsha111/YelpCamp\"\u003eYelp Camp\u003c/a\u003e [HTML, CSS, JavaScript, jQuery, Bootstrap, NodeJS, Express, MongoDB]\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003eDeployed an application where users can Create, Read, Update and Delete details of camping spots they have visited\u003c/li\u003e\n\u003cli\u003eImplemented user authentication, RESTful routes, Flash messages using MEAN stack\u003c/li\u003e\n\u003c/ul\u003e\n","description":null,"image":null,"permalink":"https://www.chandraharsha111.com/projects/","title":"Projects"},{"content":"\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e \u003cspan style=\"color:#ae81ff\"\u003eGood Judgement comes from experience and experience comes from bad judgemement - Jim Horning\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"software-development-experience\"\u003eSoftware Development Experience\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eOracle  Corporation, Software Engineer, Oct 2022 - Present\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eImplemented new features and collaborated on a Java based development platform to provide a consistent means\nof developing microservices and handled central cloud deployments.\u003c/li\u003e\n\u003cli\u003eManaged Java dependencies, identified, and fixed security vulnerabilities or CVEs for microservices.\u003c/li\u003e\n\u003cli\u003eWorked on a Cadence bundles feature to manage all the enterprise stack dependencies for enterprise Java services.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eCerner Corporation, Software Engineer, June 2018-Oct 2022\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eDeveloped automation scripts and functionality that facilitated shadowing and canarying micro service migrations.\u003c/li\u003e\n\u003cli\u003eImplemented Auth support for sidecar service, which takes in SRV request and casts it to HTTP, and deployed the service      using Helm to Kubernetes.\u003c/li\u003e\n\u003cli\u003eLed API reviews across micro services to eliminate redundant APIs in Millennium, an EHR product.\u003c/li\u003e\n\u003cli\u003eLeveraged Jenkins to create multibranched pipelines across several libraries to improve CI-CD.\u003c/li\u003e\n\u003cli\u003eCreated endpoints in Spring MVC to add export functionality, implemented CRUD operations using Hibernate (HQL), Implemented UI using HTML, CSS, JavaScript, jQuery Data Table API to create responsive web pages.\u003c/li\u003e\n\u003cli\u003eMentored new associates that joined between Aug 2020 to Dec 2022\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eCognizant technology solutions, 2015-2016\u003c/em\u003e\n\u003cul\u003e\n\u003cli\u003eFormulated and Implemented unit tests in .Net Platform using FAKES in C# to ensure code functionality and to improve code coverage from 60 percent to 90 percent\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"education\"\u003eEducation\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eMasters degree in Computer Engineering from Syracuse University - 2018\u003c/li\u003e\n\u003cli\u003eBachelors degree in Computer Science from SRM University - 2015\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"interests\"\u003eInterests\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eSoftware Development\u003c/li\u003e\n\u003cli\u003eEconomics\u003c/li\u003e\n\u003cli\u003eHistory\u003c/li\u003e\n\u003cli\u003ePsychology\u003c/li\u003e\n\u003c/ul\u003e\n","description":null,"image":null,"permalink":"https://www.chandraharsha111.com/about/","title":"Chandra Harsha Jupalli"}]